{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('base': conda)",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Pipeline\n",
    "\n",
    "In this section I will ensamble all the step to create the proper Pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib qt\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pipeline as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of calibration images\n",
    "images = glob.glob('../test_images/*.jpg')\n",
    "i = 0\n",
    "\n",
    "# Making output directory\n",
    "output_dir = \"../output_images/pipeline/\"\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for fname in images:\n",
    "    # original\n",
    "    img = mpimg.imread(fname)\n",
    "\n",
    "    # undistort image\n",
    "    img_undist = pp.undistort_image(img)\n",
    "\n",
    "    # def pipeline(img):\n",
    "    # bitmap with streigh guides\n",
    "    bitmap = pp.threshold(img_undist)\n",
    "\n",
    "    # eagle view with streigh guides\n",
    "    img_eagle_eye = pp.eagle_eye(bitmap)\n",
    "\n",
    "    x_half = int(img_eagle_eye.shape[1] / 2)\n",
    "    y_half = int(img_eagle_eye.shape[0] / 2)\n",
    "    bottom_half = img_eagle_eye[y_half:, :]\n",
    "\n",
    "    # computing poly_fit using fit_poly in pipeline\n",
    "    leftx, lefty, rightx, righty = pp.find_lane_pixels_window(bottom_half, nwindows=10, margin=100, minpix=40)\n",
    "    left_fit, right_fit, left_fitx, right_fitx, ploty = pp.fit_poly(bottom_half.shape, leftx, lefty, rightx, righty)\n",
    "\n",
    "    # Init image to plot lane\n",
    "    lines_img = np.zeros_like(img)\n",
    "\n",
    "    # Plot the are between the fitting lines\n",
    "    left_pts = np.transpose(np.array( [left_fitx, y_half + ploty]))\n",
    "    right_pts = np.transpose(np.array( [right_fitx, y_half + ploty]))\n",
    "    left_line_window = np.array([np.transpose(np.vstack([left_fitx, y_half + ploty]))])\n",
    "    right_line_window = np.array([np.flipud(np.transpose(np.vstack([right_fitx, \n",
    "                                y_half + ploty])))])\n",
    "    lane_area = np.hstack((left_line_window, right_line_window))\n",
    "    cv2.fillPoly(lines_img, np.int_([lane_area]), (0,255, 0))\n",
    "\n",
    "\n",
    "    # Plot the polynomial lines onto the image\n",
    "    thikness = 20\n",
    "    lines_img = cv2.polylines(lines_img, np.int32([left_pts]), False, (255, 0, 0), thikness) \n",
    "    lines_img = cv2.polylines(lines_img, np.int32([right_pts]), False, (0, 0, 255), thikness) \n",
    "\n",
    "    # apply inverse of the eagle eye transformation\n",
    "    img_eagle_eye = pp.eagle_eye_inv(lines_img)\n",
    "\n",
    "    # combine with original image\n",
    "    combined_img = cv2.addWeighted(img_undist, 1, img_eagle_eye, 0.6, 0)\n",
    "\n",
    "    # tranfomation to real space\n",
    "    left_fit_real, right_fit_real = pp.fit_to_real_space(left_fit, right_fit)\n",
    "    left_fitx_real = left_fitx * pp.xm_per_pix\n",
    "    right_fitx_real = right_fitx * pp.xm_per_pix\n",
    "    ploty_real = ploty * pp.ym_per_pix\n",
    "\n",
    "    position = pp.car_position(img, ploty_real, left_fit_real, right_fit_real)\n",
    "    # computing curvature\n",
    "    left_curverad, right_curverad = pp.measure_curvature(ploty_real, left_fit_real, right_fit_real)\n",
    "    curve_radious = (left_curverad + right_curverad) / 2\n",
    "\n",
    "    string_curvature = \"The curvature radios is \" + \"{:.2f}\".format(curve_radious) + \"m\"\n",
    "    string_position = \"The car position is \" + \"{:.2f}\".format(position) + \"m from the center\"\n",
    "    font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfCurvatureText = (100,100)\n",
    "    bottomLeftCornerOfPositionText = (100,150)\n",
    "    fontScale              = 1\n",
    "    fontColor              = (255,255,255)\n",
    "    lineType               = 2\n",
    "    cv2.putText(combined_img, string_curvature, bottomLeftCornerOfCurvatureText, font, fontScale, fontColor, lineType)\n",
    "    cv2.putText(combined_img, string_position, bottomLeftCornerOfPositionText, font, fontScale, fontColor, lineType)\n",
    "\n",
    "    f = plt.figure(i)\n",
    "    i = i + 1\n",
    "    plt.imshow(combined_img)\n",
    "\n",
    "    f.savefig(output_dir + os.path.basename(fname))"
   ]
  },
  {
   "source": [
    "After looking the full assemble we can see that the fitting in the images is done corretly:\n",
    "\n",
    "![Lanes Image](../output_images/pipeline/test2.jpg) \n",
    "\n",
    "![Lanes Image](../output_images/pipeline/straight_lines1.jpg) "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "So I procede to write the final version in the pipeline.py and process the video"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "t:   0%|          | 2/1260 [00:00<01:30, 13.89it/s, now=None]Moviepy - Building video ../output_images/pipeline/project_video.mp4.\n",
      "Moviepy - Writing video ../output_images/pipeline/project_video.mp4\n",
      "\n",
      "Moviepy - Done !\n",
      "Moviepy - video ready ../output_images/pipeline/project_video.mp4\n",
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import pipeline as pp\n",
    "\n",
    "global left_fit\n",
    "global right_fit\n",
    "\n",
    "pipeline = pp.Pipeline()\n",
    "\n",
    "def process_image(image):\n",
    "    result = pipeline.step(image)\n",
    "\n",
    "    return result\n",
    "\n",
    "clip1 = VideoFileClip(\"../project_video.mp4\")\n",
    "video_output = '../output_images/pipeline/project_video.mp4'\n",
    "\n",
    "white_clip = clip1.fl_image(process_image)\n",
    "%time white_clip.write_videofile(video_output, audio=False)"
   ]
  }
 ]
}